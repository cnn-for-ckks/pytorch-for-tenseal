# TODO: Implement the ReLU function for evaluation.

# NOTE: ReLU is a non-linear operation that is used in neural networks, so it's hard to model using polynomial approximations.
